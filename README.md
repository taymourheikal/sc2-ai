# Reinforcement Learning with StarCraft II

This repo will track my progress in building a fully autonomous StarCraft II smart agent using various techniques of Reinforcement Learning (RL). StarCraft II is a real-time strategy game developed by Blizzard Entertainment. In contrast to First-Person Shooter (FPS) or 
Multiplayer Online Battle Arena (MOBA) games which can be more easily "learned" by an agent due to their reliance on player mechanics, Real-Time Strategy (RTS) games are considered more complex due to their strategic nature.

The state of the art in RL has taken leaps and bounds in the last few years, most noticeably when DeepMind's AlphaGo agent was able to beat Lee Sedol, the world's number 1 Go player: https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol

Google's DeepMind has also had success in building RL agents for Atari games, but now has set it's sights on a more daunting task in StarCraft II. Along with Blizzard Entertainment, DeepMind has released what they call the SC2 Learning Environment which they hope will accelerate AI research in the real-time strategy game: https://deepmind.com/blog/deepmind-and-blizzard-open-starcraft-ii-ai-research-environment/

**Here's an idea of what it may look like (one day):** https://www.youtube.com/watch?v=WEOzide5XFc
